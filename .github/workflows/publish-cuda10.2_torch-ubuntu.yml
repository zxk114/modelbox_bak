name: Publish cuda102_torch-develop-ubuntu
on:
  workflow_dispatch:
  push:
    tags:
      - v*
env:
  BUILD_TYPE: Release
  CUDA_VER: "10-2"
  CUDA_VERSION: "10.2"
  CUDA_CUDART_VERSION: "10.2.89-1"
  NVIDIA_CUDA_VERSION: "10.2.89"
  TORCH_VERSION: "1.9.1"
  NVIDIA_REQUIRE_CUDA: "'cuda>=10.2 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441'"
  IMAGE_NAME_DEV: "zxk114/modelbox-develop-libtorch_1.9.1-cuda_10.2-ubuntu-x86_64"
  IMAGE_NAME_RUN: "zxk114/modelbox-runtime-libtorch_1.9.1-cuda_10.2-ubuntu-x86_64"
  IMAGE_VERSION: "v1.1.3"

jobs:
  compile:
    runs-on: ubuntu-latest
    container: ubuntu:18.04
    steps:
    - uses: actions/checkout@v2
    - name: Install dependencies
      run: |
        ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
        echo "Asia/Shanghai" > /etc/timezone
        apt-get update
        apt-get upgrade -y
        apt-get remove --purge python3-apt
        apt-get install --no-install-recommends -y dbus iproute2 gnupg2 curl ca-certificates
        apt-get install -y python3.7-dev python3-pip python3-apt python3-setuptools
        apt-get install -y \
            build-essential unzip ffmpeg sudo bash vim gdb git doxygen autoconf cmake openssh-server \
            python3-wheel python3-numpy python3-opencv libopencv-dev pkg-config kmod net-tools pciutils \
            libssl-dev libcpprest-dev libswscale-dev libavformat-dev graphviz libgraphviz-dev libfuse-dev \
            libprotobuf-c-dev protobuf-c-compiler duktape-dev libmosquitto-dev
        echo "Install dependencies success"
    - name: Install cuda+trt
      run: |
        curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub | apt-key add -
        cp -af ./docker/repo/*.list /etc/apt/sources.list.d/

        apt-get update
        apt install -y --no-install-recommends \
            cuda-cudart-${CUDA_VER}=${CUDA_CUDART_VERSION} \
            cuda-compat-${CUDA_VER} \
            cuda-minimal-build-${CUDA_VER} \
            cuda-libraries-dev-${CUDA_VER} \
            cuda-command-line-tools-${CUDA_VER} \
            libcublas10=10.2.2.89-1 \
            libcublas-dev=10.2.2.89-1
        ln -s cuda-${CUDA_VERSION} /usr/local/cuda

        rm -f /etc/apt/sources.list.d/cuda.list
        apt update
        apt install -y --no-install-recommends \
            libcudnn8=8.0.0.180-1+cuda10.2 \
            libcudnn8-dev=8.0.0.180-1+cuda10.2
        ln -s /usr/local/cuda/lib64/libcublas.so.10 /usr/local/lib/libcublas.so.10.2
        cp -af /usr/local/cuda/compat/* /usr/local/lib/

        curl -LJO https://download.pytorch.org/libtorch/cu102/libtorch-cxx11-abi-shared-with-deps-1.9.1%2Bcu102.zip
        unzip libtorch-*.zip -d . >/dev/null 2>&1
        cp -af libtorch/* /usr/local/
 
    - name: Install ThirdParty
      run: |
        curl -fsSL https://deb.nodesource.com/setup_16.x | bash -
        apt-get install -y nodejs
        npm install -g npm@latest
        npm install -g @angular/cli
        npm -v && node -v
        npm cache clean --force

        curl -LJO https://download.java.net/java/GA/jdk17/0d483333a00540d886896bac774ff48b/35/GPL/openjdk-17_linux-x64_bin.tar.gz
        curl -LJO https://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz
        curl -LJO https://github.com/zxk114/modelbox/releases/download/binary/obs-dev.tar.gz
        for tar in *.tar.gz; do tar zxf $tar -C /usr/local/ && echo "$tar"; done

        curl -LJO https://github.com/zxk114/modelbox/releases/download/binary/Video_Codec_SDK_9.1.23.zip
        unzip -j Video_Codec_SDK_9.1.23.zip \
            Video_Codec_SDK_9.1.23/include/cuviddec.h \
            Video_Codec_SDK_9.1.23/include/nvcuvid.h \
            Video_Codec_SDK_9.1.23/include/nvEncodeAPI.h \
            -d /usr/local/include
        unzip -j Video_Codec_SDK_9.1.23.zip \
            Video_Codec_SDK_9.1.23/Lib/linux/stubs/x86_64/libnvcuvid.so \
            Video_Codec_SDK_9.1.23/Lib/linux/stubs/x86_64/libnvidia-encode.so \
            -d /usr/local/lib
        ln -s libnvcuvid.so /usr/local/lib/libnvcuvid.so.1

        yes | python3 -m pip install --upgrade pip
        yes | pip3 install pillow numpy wheel
    - name: CMake
      run: |
        pwd
        export JAVA_HOME=/usr/local/jdk-17
        export MAVEN_HOME=/usr/local/apache-maven-3.8.4
        export LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs:/usr/local/lib${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
        export PATH=/usr/local/cuda/bin:$JAVA_HOME/bin:$MAVEN_HOME/bin${PATH:+:${PATH}}
        export PKG_CONFIG_PATH=/usr/lib/x86_64-linux-gnu/pkgconfig${PKG_CONFIG_PATH:+:${PKG_CONFIG_PATH}}
        rm -f /usr/bin/python3 /usr/bin/python
        update-alternatives --install /usr/bin/python python /usr/bin/python3.7 100
        update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 100
        update-alternatives --config python3
        ls -lh /usr/bin/python*
        /usr/bin/python -V && /usr/bin/python3 -V
        ls -lh .
        ldconfig
        mkdir build
        cd build
        cmake .. -DCMAKE_BUILD_TYPE=${{env.BUILD_TYPE}} -DWITH_WEB_UI=on
    - name: Build
      working-directory: ./build
      run: |
        make package -j4
        rm -f release/*.rpm
        ls -lh release
        filecount=$(ls release | wc -l)
        dpkgcount=$(ls release | egrep "*.deb" | wc -l)
        artifacts_file=$(ls ${artifacts_path} | grep "cuda"| wc -l)
        if [ ${filecount} -ge 13 ] && [ ${dpkgcount} -ge 11 ] && [ ${artifacts_file} -eq 2 ]; then
            echo "compile success"
        else
            echo "compile failed"
            exit 1
        fi
    - name: Prepare Artifact
      run: |
        mkdir ./artifact
        cp -af ./build/release ./artifact/
        ls -lh ./artifact
    - name: Upload Artifact
      uses: actions/upload-artifact@v2
      with:
        name: modelbox-artifact
        path: ./artifact

  build_develop_image:
    runs-on: ubuntu-latest
    needs: compile
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
      - name: Login to DockerHub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME_zxk }}
          password: ${{ secrets.DOCKERHUB_TOKEN_zxk }}
      - name: Download Artifact
        uses: actions/download-artifact@v2
        with:
          name: modelbox-artifact
          path: ./
      - name: Prepare and Recheck
        run: |
          ls -lh .
          ls -lh ./release
      - name: Build and Push
        id: docker_build
        uses: docker/build-push-action@v2
        with:
          push: true
          context: .
          file: ./docker/Dockerfile.cuda.develop.ubuntu
          build-args: |
            CUDA_VER=${{ env.CUDA_VER }}
            CUDA_VERSION=${{ env.CUDA_VERSION }}
            TORCH_VERSION=${{ env.TORCH_VERSION }}
            CUDA_CUDART_VERSION=${{ env.CUDA_CUDART_VERSION }}
            NVIDIA_CUDA_VERSION=${{ env.NVIDIA_CUDA_VERSION }}
            NVIDIA_REQUIRE_CUDA=${{ env.NVIDIA_REQUIRE_CUDA }}
          tags: |
            ${{ env.IMAGE_NAME_DEV }}:latest
            ${{ env.IMAGE_NAME_DEV }}:${{ env.IMAGE_VERSION }}

  build_runtime_image:
    runs-on: ubuntu-latest
    needs: compile
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
      - name: Login to DockerHub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME_zxk }}
          password: ${{ secrets.DOCKERHUB_TOKEN_zxk }}
      - name: Download Artifact
        uses: actions/download-artifact@v2
        with:
          name: modelbox-artifact
          path: ./
      - name: Prepare and Recheck
        run: |
          ls -lh .
          ls -lh ./release
      - name: Build and Push
        id: docker_build
        uses: docker/build-push-action@v2
        with:
          push: true
          context: .
          file: ./docker/Dockerfile.cuda.runtime.ubuntu
          build-args: |
            CUDA_VER=${{ env.CUDA_VER }}
            CUDA_VERSION=${{ env.CUDA_VERSION }}
            TORCH_VERSION=${{ env.TORCH_VERSION }}
            CUDA_CUDART_VERSION=${{ env.CUDA_CUDART_VERSION }}
            NVIDIA_CUDA_VERSION=${{ env.NVIDIA_CUDA_VERSION }}
            NVIDIA_REQUIRE_CUDA=${{ env.NVIDIA_REQUIRE_CUDA }}
          tags: |
            ${{ env.IMAGE_NAME_RUN }}:latest
            ${{ env.IMAGE_NAME_RUN }}:${{ env.IMAGE_VERSION }}
